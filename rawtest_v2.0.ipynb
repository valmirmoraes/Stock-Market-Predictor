{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6af3db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (6269, 5)\n",
      "y shape: (6269,)\n",
      "Accuracy: 0.5167464114832536\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.43      0.47       628\n",
      "           1       0.51      0.60      0.55       626\n",
      "\n",
      "    accuracy                           0.52      1254\n",
      "   macro avg       0.52      0.52      0.51      1254\n",
      "weighted avg       0.52      0.52      0.51      1254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fetch stock data\n",
    "stock_data = yf.Ticker(\"AAPL\")  # Example: Apple Inc.\n",
    "stock_data = stock_data.history(period=\"max\")\n",
    "\n",
    "stock_data = stock_data.loc[\"2000-01-01\":\"2024-12-31\"].copy()\n",
    "\n",
    "# Prepare features\n",
    "stock_data['Return'] = stock_data['Close'].pct_change()\n",
    "stock_data['Moving_Avg_5'] = stock_data['Close'].rolling(window=5).mean()\n",
    "stock_data['Moving_Avg_20'] = stock_data['Close'].rolling(window=20).mean()\n",
    "stock_data['Volatility'] = stock_data['Close'].rolling(window=5).std()\n",
    "\n",
    "# Target Variables\n",
    "stock_data['Price_Tomorrow'] = stock_data['Close'].shift(-1)\n",
    "stock_data['Direction'] = (stock_data['Price_Tomorrow'] > stock_data['Close']).astype(int)  # 1 for Up, 0 for Down\n",
    "\n",
    "# stock_data\n",
    "\n",
    "# Drop rows with NaN values introduced by rolling and shifting\n",
    "stock_data = stock_data.dropna()\n",
    "\n",
    "# Features and target\n",
    "X = stock_data[['Close', 'Return', 'Moving_Avg_5', 'Moving_Avg_20', 'Volatility']]\n",
    "y = stock_data['Direction']\n",
    "\n",
    "# Align X and y to ensure proper indexing\n",
    "X, y = X.align(y, axis=0)\n",
    "\n",
    "# Check alignment\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb9afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a library like yfinance to fetch data for major indices, such as:\n",
    "## S&P 500 (^GSPC)\n",
    "## Nasdaq Composite (^IXIC)\n",
    "## Dow Jones Industrial Average (^DJI)\n",
    "\n",
    "# Fetch S&P 500 data\n",
    "sp500 = yf.Ticker(\"^GSPC\")  # Example: Apple Inc.\n",
    "sp500 = sp500.history(period=\"max\")\n",
    "\n",
    "sp500 = sp500.loc[\"2000-01-01\":\"2024-12-31\"].copy()\n",
    "\n",
    "sp500['SP500_Return'] = sp500['Close'].pct_change()\n",
    "\n",
    "# Fetch Nasdaq Composite data\n",
    "NC = yf.Ticker(\"^GSPC\")  # Example: Apple Inc.\n",
    "NC = NC.history(period=\"max\")\n",
    "\n",
    "NC = NC.loc[\"2000-01-01\":\"2024-12-31\"].copy()\n",
    "\n",
    "sp500['SP500_Return'] = sp500['Close'].pct_change()\n",
    "\n",
    "# Align dates with your stock data\n",
    "sp500 = sp500[['SP500_Return']].reset_index()\n",
    "stock_data = stock_data.reset_index()\n",
    "\n",
    "# Merge S&P 500 data with stock data\n",
    "stock_data = pd.merge(stock_data, sp500, on='Date', how='left')\n",
    "\n",
    "# Drop NaN values introduced by alignment\n",
    "stock_data = stock_data.dropna()\n",
    "\n",
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b32861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ETFs (Exchange Traded Funds) representing specific sectors. Examples include:\n",
    "## Technology: XLK\n",
    "## Healthcare: XLV\n",
    "## Financials: XLF\n",
    "### Fetch and process data for relevant ETFs as with the S&P 500.\n",
    "\n",
    "\n",
    "# Fetch Technology sector ETF data\n",
    "tech_etf = yf.Ticker(\"XLK\")  # Example: Apple Inc.\n",
    "tech_etf = tech_etf.history(period=\"max\")\n",
    "\n",
    "tech_etf = tech_etf.loc[\"2000-01-01\":\"2024-12-31\"].copy()\n",
    "\n",
    "tech_etf['Tech_Return'] = tech_etf['Close'].pct_change()\n",
    "\n",
    "# Merge Technology ETF data with stock data\n",
    "tech_etf = tech_etf[['Tech_Return']].reset_index()\n",
    "stock_data = pd.merge(stock_data, tech_etf, on='Date', how='left')\n",
    "\n",
    "# Drop NaN values introduced by alignment\n",
    "stock_data = stock_data.dropna()\n",
    "\n",
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lagged_features(df, columns, lags):\n",
    "    \"\"\"\n",
    "    Adds lagged features for specified columns.\n",
    "    Args:\n",
    "        df (DataFrame): The original DataFrame.\n",
    "        columns (list): List of column names to lag.\n",
    "        lags (list): List of lag periods to apply.\n",
    "    Returns:\n",
    "        DataFrame: Updated DataFrame with lagged features.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        for lag in lags:\n",
    "            df[f\"{col}_lag_{lag}\"] = df[col].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Add lagged features\n",
    "lag_columns = ['Close', 'SP500_Return', 'Tech_Return']\n",
    "lags = [1, 3, 7]\n",
    "stock_data = add_lagged_features(stock_data, lag_columns, lags)\n",
    "\n",
    "# Drop NaN values introduced by lagging\n",
    "stock_data = stock_data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700de0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_news_sentiment(ticker):\n",
    "    \"\"\"\n",
    "    Fetches sentiment data for a given stock ticker from a news API.\n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol.\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with sentiment scores.\n",
    "    \"\"\"\n",
    "    # Example: Using a hypothetical API to fetch sentiment data\n",
    "    import requests\n",
    "    \n",
    "    # Replace with actual API endpoint and parameters\n",
    "    api_url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        'q': ticker,\n",
    "        'apiKey': 'your_api_key',\n",
    "        'sortBy': 'relevance',\n",
    "        'language': 'en',\n",
    "    }\n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Placeholder: Compute sentiment score (e.g., positive, neutral, negative)\n",
    "    sentiment_scores = []\n",
    "    for article in data.get('articles', []):\n",
    "        # Example sentiment logic: Positive if \"positive\" keyword found\n",
    "        sentiment = 1 if \"positive\" in article['title'].lower() else 0\n",
    "        sentiment_scores.append({'date': article['publishedAt'], 'sentiment': sentiment})\n",
    "    \n",
    "    sentiment_df = pd.DataFrame(sentiment_scores)\n",
    "    sentiment_df['date'] = pd.to_datetime(sentiment_df['date']).dt.date\n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_macro_indicators(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetches macroeconomic indicators such as interest rates and inflation.\n",
    "    Args:\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with macroeconomic indicators.\n",
    "    \"\"\"\n",
    "    from fredapi import Fred\n",
    "\n",
    "    # Initialize FRED API with your API key\n",
    "    fred = Fred(api_key='your_fred_api_key')\n",
    "\n",
    "    # Fetch indicators (examples: Federal Funds Rate, CPI)\n",
    "    interest_rates = fred.get_series('FEDFUNDS', start_date, end_date)\n",
    "    inflation = fred.get_series('CPIAUCSL', start_date, end_date)\n",
    "\n",
    "    # Combine into a DataFrame\n",
    "    macro_data = pd.DataFrame({\n",
    "        'Date': interest_rates.index,\n",
    "        'Interest_Rate': interest_rates.values,\n",
    "        'Inflation': inflation.reindex(interest_rates.index, method='ffill').values\n",
    "    }).reset_index(drop=True)\n",
    "    return macro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature for relative strength\n",
    "stock_data['Relative_SP500'] = stock_data['Return'] - stock_data['SP500_Return']\n",
    "stock_data['Relative_Tech'] = stock_data['Return'] - stock_data['Tech_Return']\n",
    "\n",
    "# Moving averages\n",
    "stock_data['SP500_MA_5'] = stock_data['SP500_Return'].rolling(window=5).mean()\n",
    "stock_data['Tech_MA_5'] = stock_data['Tech_Return'].rolling(window=5).mean()\n",
    "\n",
    "stock_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f425f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = stock_data[['Close', 'Return', 'Moving_Avg_5', 'Moving_Avg_20', 'Volatility',\n",
    "                'SP500_Return', 'Tech_Return', 'Relative_SP500', 'Relative_Tech', \n",
    "                'SP500_MA_5', 'Tech_MA_5']]\n",
    "y = stock_data['Direction']\n",
    "\n",
    "# Align X and y to ensure proper indexing\n",
    "X, y = X.align(y, axis=0)\n",
    "\n",
    "# Check alignment\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "# Synthetic Minority Oversampling Technique (SMOTE) generates synthetic samples for the minority class\n",
    "smote = SMOTE(random_state=42) \n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best model for evaluation\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
